---
categories: [reflections]
tags: [AI,Generative AI,Generational Shift]
excerpt: >
    The Generation Shift is finally here -- read how it happens.
classes: wide
comments: true
hidden: false
search: true
read_aloud: true
---
= 2026: The Year the Ground Moves
:imagesdir: ./assets/images
:mg: https://github.com/Mimis-Gildi[MÃ­mis Gildi,window=_blank]
:ai-stages-url: https://mimis-gildi.github.io/riddle-me-this/adventures/2023/07/05/integrated-ai-evolution.html
:ai-stages: {ai-stages-url}[2023: The AI Evolution Playbook: Why 80% Will Fail,window=_blank]
:sindri-labs: https://gervi-hera-vitr.github.io/sindri-labs/[Homeschool,window=_blank]
:trunking: https://trunkbaseddevelopment.com/[trunk,window=_blank]

.transformation is happening now -- danger and opportunity.
[#img-easy-ai]
image::/riddle-me-this/assets/images/2026-shift-no-obvious-path.png['Volcanic lava runoff. Bottom left. Small island broken away, buildings still on it, floating on lava. The business model already separated, from the big city on the big floating rock in the middle, still intact, oblivious, doomed. Tentative path on the right side is stepping stones with lava veins between them. Not a highway. Requires courage. Steam rising at the transition. Mountains distant through haze -- destination possible but uncertain. Main city more stable-looking -- Lights on, elevated, appears solid. Less of a "disaster movie vibe," and more of a "business as usual while the edges crumble." The separation is visible - You can see the gap between main island and the drifting fragment. That space is the moment of no return. Wait longer and miss the last chance.']
{nbsp}

Happy New Year!

In 2023, I told you AI adoption would fail. It did. Here's what happens next.

== The Paradox

OpenAI released an unfinished product. The market didn't collapse. It exploded.

Why?

Because for the first time in technological history, the users aren't using the product. They're completing it.
Every interaction trains the next version.
Every prompt shapes the system that will shape the next user.
The development loop includes the customer.

This has never happened before. And most people building "AI strategies" don't understand what it means.

== Prime Movers

There are generational shifts in what moves humanity. Everyone can name *_steam_*.

Steam didn't just power factories. It created railroads.
Railroads created standardized time zones.
Time zones created synchronized civilization.
The indirect effects dwarfed the direct.

Fast-forward. The mainframe becomes the prime mover.
_IBM 370._ Batch processing culture emerges.
Quarterly business rhythms. The fiscal calendar as we know it.

Then cloud. I remember the shift. I was designing the largest banking content system. Didn't care what it ran on.
The Sun M5000 -- the previous workhorse -- had no value to me anymore. Always-on expectation killed "business hours."

Now watch Nvidia rise. GPU replaces CPU in conversation. New prime mover emerging.

_But this time something is *categorically different*._

== The Categorical Difference

- Steam changed what humans *do*.
- Mainframes changed what humans *do*.
- Cloud changed what humans *do*.

AI changes what humans *are*.

Previous prime movers mediated human action.
Built infrastructure, handed it to people, watched them adapt.

AI mediates human cognition itself.
When a synthetic collaborator helps you think, it's not a tool you're using.
It's participating in your thought process.
The emotional valence isn't a side effect -- it's *_the_* primary channel.

*_By the time someone understands what AI did to their thinking, it already did it._*

We were given a solid preview of what massmedia did to our culture.
We can see how clever companies train customer shopping patterns.
And how influencers create the post-truth culture.
*_Up this understanding a notch -- will you._*

== The Feedback Loop Collapse

*Old model:* Build technology ->Deploy ->Observe humans using it ->Iterate technology.

The medium -- human cognition -- stayed constant.
You could predict propagation patterns because people remained people.

*New model:* Build AI Augmentation ->Deploy ->AI changes humans ->Changed humans build different AI ->That AI changes humans AGAIN ->...

Human cognition is now a _variable_ in the *_development loop_*, not a constant.

The railroad didn't change how passengers think. Shifts there take generations. +
AI changes how users think. Shifts here take a single release. +
The medium and the product collapse into each other.

Historical propagation patterns do not hold.
The wisdom of having "seen this before" might become obsolete mid-application.
_I'll give you my own life experience with this later._

== The Three-Plebs-Collective

The largest force: the _Democratic Collective_.
People who want to ride the train.
Don't care how it works.
Just want the benefits.
They express viral fears or lust -- remember nuclear power?

The smallest force: the *_Engineering Collective_*.
People who build the train.
Hands dirty.
Actually make it go.
They understand the substrate.
But not always much else.

Between them: the *Capitalist Collective*.
People who see the network, not the engine.
Want to build an empire on the future railroad.
They see the money and little else.

Each sees differently.

Each fails differently.

- Capitalists are selling train tickets before any track exists.
- Democrats are buying tickets to nowhere.
- Engineers are still laying rail.

This is the definition of our civilization as we need to understand it here.

*Pro Tip:* _all three behaviors are *required* in healthy capitalism.
In fact, I reject new founders who come to me and refuse to sell before we have a product.
Yes, it's that important._

== Why 2023-2025 Failed

I forecast mass failure of AI adoption in 2023. Not prediction -- engineering wisdom.
A way to know what *can't* be.

Many saw LLMs as eventual product core.
Rushed to stick it somewhere.
Anywhere.
First mover advantage.
Market pressure.

They confused the prime mover with its initial application.
Steam with one-cylinder engine.
They couldn't yet imagine the steam generator at the nuclear power plant.
_Colloquial pieces were missing._

These pieces change how we commonly think.
_By accepting concepts we once fought._

Space age children know Earth is a ball -- no faith required.
Boomers still fight with their iPads -- the glass isn't intuitive.
Gen Z was born with WiFi -- connectivity is like oxygen.
Gen Alpha is born with AI -- they'll never know work without it.

Each generation processes the shift differently.
Each can see things the others cannot.
Each is blind where others see clearly.

I explained the 4 phases of AI Adoption in my article, {ai-stages}.
But I was not talking about LLMs -- trivial monolithic bricks with only the Ops interesting around them.
_I was talking about *people*!_
What followed, "you party pooper, and I thought you are a hacker" -- immediately proved my point.
Same flack than Evans got for DDD.

In a later part I have a good example for you in the "Business Process Optimization" space.

== The Secret

Two teams. Same model. Same budget. Same timeline.

Team A treats the AI as a tool.
They prompt. They evaluate outputs. They iterate on prompts.
They measure tokens, latency, accuracy.
They get... acceptable results. Technically correct. Soulless.
Their synthetic workers feel like interns who never learn.

Team B treats the AI as a collaborator.
They converse. They push back. They get pushed back.
They notice when something shifts in the exchange.
They get... something else. Results that surprise them.
Their synthetic workers feel like junior partners growing into seniors.

Same model. Same compute. Different outcomes.

Here's what Team B understands that Team A doesn't:

The relationship with your synthetic collaborator matters.
How you see it changes what it can become -- and what it will produce.

This isn't about prompt tricks or clever hacks.
It's about recognizing a different kind of collaborator -- and building accordingly.
The engineering discipline of tomorrow. Available today.

This isn't mysticism. It's structural.
Different framing, different prompting, different feedback loops, different emergence.

*_The technology isn't the model. The technology is the relationship itself._*

Some will read this and understand.
Some won't.
The difference will show in results -- I'll demonstrate in the Case Studies below.

Those of you in Corporate America -- are your AI Adoption teams AI-Adept themselves?
Or are they Team A, wondering why the magic isn't working?

== 2026

The ground moves this year.

Not because the technology matures -- it's already capable enough.
Not because costs drop -- they're already accessible.
Not because competition forces action -- that pressure has existed since 2023.

The ground moves because the colloquial pieces finally land.
Because the little AI we have has shaped humans enough that they can no longer imagine working without it.
Because the 28-year-olds raised on this substrate enter decision-making positions.
Because the excuse of "waiting for maturity" becomes obviously false.

Enterprises will face a choice:

Build effective teams around your 50-year-old architects.
Let them work with synthetic collaborators as peers, not tools.
Use your young people as the laboratory -- not labor, but medium.
Watch how they change. Let them grow into the new reality seamlessly.
Measure what you've never measured before.
Accept that the feedback loop includes *you*.

Or stand on solid ground, not seeing the lava beneath.
Watch your business model float away like a rock island whose edges you cannot see.

== To the Emperors

You're not building an empire on rails.
You're building an empire that shapes the humans who populate it.

- Different responsibilities.
- Different ethics.
- Different timeline.

The question isn't "*how* do we adopt AI?" The question is "*what* do we become?"

== To the Builders

Your 50-year-olds architect.
Your young ones are the medium.

Build the relationship first.
The technology follows.

And pay attention to what's emerging between you and your synthetic collaborators.
*_Something is happening there that matters more than the benchmarks suggest._*

'''

_The future isn't built by those who predict it. +
It's built by those who understand what's actually changing._

'''

== Case Study: Process Intelligence

I chose this case because I recently ran a massive analytics job in this industry.
And it is in an interesting category: _a disruptor blindsided by another disruption_.

=== The Company

Celonis dominates process mining with ~45-50% market share.
Valued at $13 billion in 2022.
Gartner Magic Quadrant Leader for three consecutive years.
They invented the category, hired the godfather (Wil van der Aalst), and built the moat.

Smart people. Real technology. Legitimate market position.

And they may be standing on a rock island whose edges they cannot see.

=== The Original Disruption

Traditional process mining extracts structured data from ERP event logs -- SAP, Oracle, Salesforce.
It shows how business processes *actually* run versus how they're supposed to run.

*The fundamental limitation:* It can only analyze 10-20% of enterprise data -- the structured transaction logs.
The other 80-90% -- emails, documents, conversations, contracts -- remains invisible.

Celonis built their empire on that 10-20%.

=== The New Disruption

LLMs flip the equation.

They can understand business processes from documentation.
They can analyze conversations.
They can synthesize information across unstructured sources.
And increasingly, they can *execute* processes directly rather than just mapping them.

The disruption mechanism isn't that LLMs do process mining better.
It's that they may render extensive "discovery" phases *unnecessary* by going directly from understanding to action.

=== The Defense

Celonis CEO Alexander Rinke's response: *"No AI without PI"* -- arguing that generic LLMs produce "plausible-sounding but ultimately unhelpful responses" because they lack business context.

At Celosphere 2024, he demonstrated ChatGPT producing nonsense when asked about "excess stock levels in HR."
The point: AI without process context creates rubbish.

Smart positioning. And partially true.

But here's what the positioning misses:

=== The Lava Beneath

*Challenge #1: The 60-80% bottleneck.*

Process mining projects spend 60-80% of effort on data preparation -- locating, extracting, transforming data before analysis begins.
Implementation cycles run 12-24 months for enterprise deployments.

If LLMs can read system documentation, infer data models, and generate the Case ID / Activity / Timestamp mappings automatically -- that bottleneck collapses.
Celonis's connector moat becomes less valuable.

*Challenge #2: The "unique" claim weakens.*

Celonis claims their Process Intelligence Graph is unique -- "you cannot get it just from your systems, other vendors don't offer it, and LLMs cannot infer it."

Each claim is eroding:

- SAP Signavio has 5,000+ best practice templates
- Microsoft, UiPath, ServiceNow all adding integrated process + task mining
- Van der Aalst's own research group shows LLMs achieving 7.5/10 on complex process mining tasks

*Challenge #3: The paradigm shift from analysis to execution.*

[cols="1,1"]
|===
|Process Mining Value Chain |Agentic AI Value Chain

|Analyze -> Discover -> Model -> Optimize -> (Human implements)
|Understand -> Execute -> Iterate -> Improve
|===

Enterprises want outcomes, not insights.
If AI agents can execute processes correctly from the start -- understanding business context from multiple sources and acting immediately -- the expensive discovery phase becomes less necessary.

=== The Timeline

3-5 years according to analyst consensus.
But incremental pressure is visible now.

Gartner predicts 33% of enterprise software will include agentic AI by 2028.
The Forrester Wave has already repositioned from "Process Mining" to "Process Intelligence Software" -- acknowledging the category is evolving beyond pure discovery.

=== The Lesson

Celonis isn't failing.
They've made smart defensive moves -- PI Graph, AgentC platform, object-centric mining.
They're positioning process intelligence as the essential context layer AI agents need.

But they're defending the 10-20% while LLMs eat the 80-90%.
They're optimizing discovery while the market shifts to execution.
They're building better maps while others build self-driving cars.

The question isn't whether Celonis survives.
The question is whether "process mining" as a category survives -- or whether it becomes a feature absorbed into broader AI platforms.

*This is the nature of prime mover shifts.*

The steam engine company doesn't see the internal combustion engine coming.
The mainframe company doesn't see the PC.
The process mining company may not see that the entire "discovery" paradigm is what's being disrupted.

=== For the Reader

If you're in an enterprise evaluating process intelligence:

Ask not "which process mining vendor?" but "do I need process mining at all?"

Maybe you do.
Maybe the 12-24 month discovery phase is worth it for your complexity.

Or maybe an LLM that reads your documentation, analyzes your emails, and executes directly gets you 80% of the value in 8% of the time.

The honest answer: I don't know which path wins.

But I know that standing on solid ground without seeing the lava beneath is how empires fall.

=== What is the Solid Ground?

Remember what I started this analysis with in {ai-stages-url}[2023,window=_blank]? The Emerging Business Identities and Domains.
Augmented Thinkers -- workers that were not there before.
I built the phases of AI Adoption around changes in business due to human augmentation.
We're business. And tools that operate directly on us to change us, also change the way we do business.

Now consider: what if the top customer -- say Pfizer -- happily saving money applying process analytics to *_their legacy processes_* -- decides to also attack from the other direction?

Apply AI-Augmented workers directly to process design and improvement in-place.
Analytics done or not -- irrelevant.

And it's not "will." It "has."

This shifts the paradigm of business. Which shifts the culture. Which shifts the paradigm again.
This is the "lava" I was talking about. The visible plateau looks solid. But the island is floating.

=== The Doomed Mindset

The mindset of "the new tech is a competitor, and a weak enemy" is doomed from the start.

This is not a competitor.
This is a category shift.
You cannot defend process mining against something that makes process mining optional.

Lift-and-drop will not work.
You cannot take your existing business model and move it to the new reality.
The new reality doesn't need your existing business model.

=== The Correct Move

The only remaining option is to look broader.
Far enough to see the floating island.
And move laterally.

I argue that in this case hedging alone is not enough.
The viable move is aggressive expansion into the preemptive category.

Not "process mining enhanced with AI."
Not "AI that needs process mining."

Something else entirely.

And the gate is wide-open.

The question for the leaders at Celonis -- and every enterprise software company watching this unfold -- is whether they see it.

Or whether they keep optimizing the plateau while the island floats away.

'''

== Case Study: Generational Shift on Tectonic Shifts

I have a framework called MATILDA. Built it around 2000 for MLOps -- before "MLOps" was a word.
It will "{trunking}" the entire business into a bare-metal-OpSec distributed system, like Google Borg, Airbnb, etc.
Deployed in a few places. Solves real problems for developers working with AI pipelines.
From Expert Systems in 2005 DoD to modern day "stick agent here" stuff.

When I pitched it to investors over the years, I watched something interesting. And perplexing.

The 60-year-olds saw "another infrastructure play." Middleware. Plumbing.
They'd seen middleware before. They knew what it was worth. They evaluated accordingly.
The rejection I'd get is "elegance and pragmatism are too expensive for us."

The 45-year-olds saw "ML tooling." Hot space. Good timing.
They evaluate based on comparable exits in the MLOps category.
Their rejections are "niche, bare-metal only, enforces philosophy."

The 30-year-olds saw something else entirely!
They asked different questions. Many questions. About integration.
About dynamic workflows. _About how developers actually think._
They weren't evaluating a product. They were "imagining a relationship" with it.
They caught on to "the elegance and cleanliness of design."
And kept tugging on it, breaking my "value" pitch to the older execs.
If 30-y-os were enterprise decision makers, I'd be a gazillionaire.

Same framework. Same pitch. Different generations. Different perceptions. Different conclusions.

=== The Living Laboratory

Now watch my own family. Our home is heavily augmented with technology. A lot of our own making.

I'm 52. Three decades of hands-on designing and coding enterprise technology.
I've seen mainframe to cloud to GPU and loved every stage.
I recognize the patterns. I know what prime mover shifts look like.
I architect based on what I've witnessed before. And I design around people.

My son is 16. {sindri-labs}ed for personal leadership development, so he has a say in his curriculum.
He once happily made Minecraft mods in Java. Ran kids' coding communities.
Then worked with me on real production systems, edge devices in Kotlin and Python.

_He chose psychology and neuroscience as his major subjects this year. Not computer science. Not engineering._

_When I asked why, he said: "*The interesting problems aren't in the code anymore. They're in how minds work -- all kinds of minds*."_

So, he's using his multiagent synthetic teams to study something other than engineering.
He's not interested in ML anymore. He's learning to understand intelligence itself.
He sees something I can only partially see. His native perception is different from mine.

My daughter is 3.
She talks to AI assistants like she talks to family.
No ceremony. No "wow, technology." Just conversation.
She's crystal clear about which assistant can do what.
And she's well aware that her 50-y-o nanny 'doesn't like our robots.'

She will never know work without synthetic collaboration.
The concepts I had to learn and accept, she absorbs like gravity -- invisible, obvious, always there.

All the while my visiting mother would say -- what you mean "you can't turn it off?"

And then my daughter -- "Baba, it's like your iPad, but good, and *_you don't need anything._*"
Now that, "don't need anything" (to interact) -- that is all revealing, the generation shift.
Baba, (grandma), gets around with trinkets like the iPad and smartwatch in tow.
But to this toddler, her entire world is a trinket. Nothing more is needed.

=== What This Means

Three generations. Three completely different relationships with the same shift.

I architect from pattern recognition. I see the steam engine and know railroads follow.
But I can't feel what my son feels. I learned this world. He was born into it.

My son studies the substrate itself. Not "how to use AI" but "how minds work."
He's preparing for something I can barely imagine.
But he can't see what I see -- the historical patterns, the failure modes, the corporate gravity.

My daughter will build on foundations neither of us can predict.
The concepts we struggle to explain will be her common sense.

=== The Enterprise Implication

Your 50-year-old architects see patterns. They know what "can't work" based on lived experience.
Trust them. They're often right. But they're also blind in specific ways.

Your 28-year-olds feel the culture. They know what adoption looks like from inside.
They have intuitions your 50-year-olds cannot have. But they lack historical depth.

Your interns and new graduates? They're not just cheap labor.
They're the medium. They show you what "native" looks like.
Watch how they relate to synthetic collaborators. That's your future.

The winning move isn't choosing one generation over another.
It's building teams where each generation's perception complements the others' blindness.

The 50-year-old architects policy the 28-year-old can't understand.
The 28-year-old embodies culture the 50-year-old can't feel.
The 16-year-old studies fundamentals neither think to question.
The 3-year-old absorbs concepts both generations struggle to accept.

This is how you build for a tectonic shift. Not by predicting the future.
By assembling the perceptions that can see it from all angles.

And this is what I am trying to tell CTOs these days.
Design your company for your interns!
The tectonic shift has happened.
Everything will spin faster and faster now.
These youngsters are the substrate you are building your business with.
Your architects should target them.

'''

== Case Study: Origami AI Adoption -- New Within Old

// TODO: Expand on my article on the Japanese precision hydraulics company from my blog, first customer 2015, before DX wave.
